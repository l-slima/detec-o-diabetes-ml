import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix


# Carregar dados
df = pd.read_csv("/home/lslima/Área de Trabalho/Projetos/Diabetes/diabetes_prediction_dataset.csv")

# Renomear colunas para português
df.columns = ["Gênero","Idade","Hipertensão","Doenca_cardiaca","Historico_fumante",
              "IMC","Nivel_HbA1c","nivel_glicose_sangue","diabetes"]

# Substituir valores categóricos para português
df['Gênero'] = df['Gênero'].replace({"Female": "Feminino", "Male": "Masculino", "Other": "Outro"})
df['Historico_fumante'] = df['Historico_fumante'].replace({
    "never": "nunca",
    "No Info": "s/ inform.",
    "current": "fumante",
    "former": "ex-fum",
    "ever": "já fumou",
    "not current": "não fuma atualmente"
})

# Remover duplicatas
df = df.drop_duplicates()

# Remover registros com gênero 'Outro' (poucos casos)
df = df[df['Gênero'] != 'Outro']

# Verificar dados ausentes
print(df.isnull().sum())


# Histograma da idade
plt.hist(df['Idade'], bins=20, edgecolor='black')
plt.title('Distribuição por idade')
plt.xlabel('Idade')
plt.ylabel('Contagem')
plt.show()

# Distribuição de gênero
sns.countplot(x='Gênero', data=df)
plt.title('Distribuição de gênero')
plt.show()

# Distribuição do IMC
sns.histplot(df['IMC'], bins=30, kde=True)
plt.title('Distribuição do IMC')
plt.show()

# Distribuição de variáveis categóricas
for col in ['Hipertensão', 'Doenca_cardiaca', 'diabetes', 'Historico_fumante']:
    sns.countplot(x=col, data=df)
    plt.title(f'Distribuição da(o) {col}')
    plt.show()

# Agrupar categorias de fumantes para simplificar
def combinando_fumantes(estado):
    if estado in ["nunca", "s/ inform."]:
        return 'não-fumante'
    elif estado == 'fumante':
        return "fumante"
    elif estado in ['ex-fum', 'já fumou', 'não fuma atualmente']:
        return "ex-fumante"

df['Historico_fumante'] = df['Historico_fumante'].apply(combinando_fumantes)

# Codificação das variáveis categóricas
from sklearn.preprocessing import LabelEncoder

le_genero = LabelEncoder()
le_fumante = LabelEncoder()

df['Gênero'] = le_genero.fit_transform(df['Gênero'])
df['Historico_fumante'] = le_fumante.fit_transform(df['Historico_fumante'])

# Separar features e target
X = df.drop('diabetes', axis=1)
y = df['diabetes']

# Dividir treino e teste
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Calcular scale_pos_weight para balancear classes
neg = sum(y_train == 0)
pos = sum(y_train == 1)
scale_pos_weight = neg / pos if pos != 0 else 1
print(f"scale_pos_weight: {scale_pos_weight}")

# XGBoost
params = {
    'objective': 'binary:logistic',
    'learning_rate': 0.1,
    'max_depth': 3,
    'n_estimators': 350,
    'scale_pos_weight': scale_pos_weight,
    'use_label_encoder': False,
    'eval_metric': 'logloss',
    'random_state': 42
}
model_xgb = xgb.XGBClassifier(**params)
model_xgb.fit(X_train, y_train)

# Random Forest
model_rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=7,
    class_weight='balanced',
    random_state=42
)
model_rf.fit(X_train, y_train)

def avaliar_modelo(model, X_test, y_test, nome_modelo):
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    print(f"Relatório de classificação - {nome_modelo}")
    print(classification_report(y_test, y_pred))
    print(f"AUC ROC - {nome_modelo}: {roc_auc_score(y_test, y_proba):.4f}")

    # Matriz de confusão
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Matriz de Confusão - {nome_modelo}')
    plt.xlabel('Previsto')
    plt.ylabel('Real')
    plt.show()

avaliar_modelo(model_xgb, X_test, y_test, 'XGBoost')
avaliar_modelo(model_rf, X_test, y_test, 'Random Forest')

def plotar_importancia(model, features, nome_modelo):
    importancias = model.feature_importances_
    df_imp = pd.DataFrame({'Feature': features, 'Importância': importancias})
    df_imp = df_imp.sort_values(by='Importância', ascending=False)

    plt.figure(figsize=(10,6))
    sns.barplot(x='Importância', y='Feature', data=df_imp)
    plt.title(f'Importância das variáveis - {nome_modelo}')
    plt.show()

plotar_importancia(model_xgb, X.columns, 'XGBoost')
plotar_importancia(model_rf, X.columns, 'Random Forest')
